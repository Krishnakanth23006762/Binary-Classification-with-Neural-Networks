{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca062588",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/tawfikelmetwally/census-income-dataset?dataset_version_number=2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 691k/691k [00:01<00:00, 503kB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n",
      "Path to dataset files: C:\\Users\\admin\\.cache\\kagglehub\\datasets\\tawfikelmetwally\\census-income-dataset\\versions\\2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"tawfikelmetwally/census-income-dataset\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b49f0e36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/30, Loss: 0.3413\n",
      "Epoch 10/30, Loss: 0.3343\n",
      "Epoch 15/30, Loss: 0.3331\n",
      "Epoch 20/30, Loss: 0.3267\n",
      "Epoch 25/30, Loss: 0.3281\n",
      "Epoch 30/30, Loss: 0.3269\n",
      "\n",
      "Test Loss: 0.3236\n",
      "Test Accuracy: 84.75%\n",
      "\n",
      "Prediction: <=50K\n"
     ]
    }
   ],
   "source": [
    "# ===============================================\n",
    "# Census Income Classification (PyTorch) - CORRECTED\n",
    "# ===============================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# -----------------------------\n",
    "# 1. Load & Prepare Data\n",
    "# -----------------------------\n",
    "df = pd.read_csv(\"adult.csv\")\n",
    "\n",
    "# ### FIX 1: Strip whitespace from all object columns ###\n",
    "for col in df.select_dtypes(include=['object']).columns:\n",
    "    df[col] = df[col].str.strip()\n",
    "\n",
    "\n",
    "# Define columns (consistent naming)\n",
    "categorical_cols = [\n",
    "    \"Workclass\", \"Education\", \"Marital Status\", \"Occupation\",\n",
    "    \"Relationship\", \"Race\", \"Gender\", \"Native Country\"\n",
    "]\n",
    "\n",
    "continuous_cols = [\n",
    "    \"Age\", \"Final Weight\", \"EducationNum\",\n",
    "    \"Capital Gain\", \"capital loss\", \"Hours per Week\"\n",
    "]\n",
    "\n",
    "label_col = \"Income\"\n",
    "\n",
    "# Encode categorical columns\n",
    "label_encoders = {}\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col].astype(str))\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# Encode label\n",
    "label_encoder = LabelEncoder()\n",
    "df[label_col] = label_encoder.fit_transform(df[label_col])\n",
    "\n",
    "# Separate arrays\n",
    "cats = np.stack([df[col].values for col in categorical_cols], axis=1)\n",
    "conts = np.stack([df[col].values for col in continuous_cols], axis=1)\n",
    "labels = df[label_col].values\n",
    "\n",
    "# Convert to tensors\n",
    "cats = torch.tensor(cats, dtype=torch.int64)\n",
    "conts = torch.tensor(conts, dtype=torch.float)\n",
    "labels = torch.tensor(labels, dtype=torch.long)\n",
    "\n",
    "# Create dataset\n",
    "dataset = TensorDataset(cats, conts, labels)\n",
    "\n",
    "# Split dataset (80% train / 20% test)\n",
    "total_size = len(dataset)\n",
    "train_size = int(total_size * 0.8)\n",
    "test_size = total_size - train_size\n",
    "\n",
    "train_ds, test_ds = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "# DataLoaders\n",
    "train_dl = DataLoader(train_ds, batch_size=64, shuffle=True)\n",
    "test_dl = DataLoader(test_ds, batch_size=64)\n",
    "\n",
    "# -----------------------------\n",
    "# 2. Define Model\n",
    "# -----------------------------\n",
    "class TabularModel(nn.Module):\n",
    "    def __init__(self, emb_sizes, n_cont, out_sz, hidden_sz=50, p=0.4):\n",
    "        super().__init__()\n",
    "        self.embeds = nn.ModuleList([nn.Embedding(c, s) for c, s in emb_sizes])\n",
    "        self.emb_drop = nn.Dropout(p)\n",
    "        self.bn_cont = nn.BatchNorm1d(n_cont)\n",
    "\n",
    "        n_emb = sum(e.embedding_dim for e in self.embeds)\n",
    "        self.fc1 = nn.Linear(n_emb + n_cont, hidden_sz)\n",
    "        self.fc2 = nn.Linear(hidden_sz, out_sz)\n",
    "        self.dropout = nn.Dropout(p)\n",
    "\n",
    "    def forward(self, x_cat, x_cont):\n",
    "        embeddings = [e(x_cat[:, i]) for i, e in enumerate(self.embeds)]\n",
    "        x = torch.cat(embeddings, 1)\n",
    "        x = self.emb_drop(x)\n",
    "\n",
    "        x_cont = self.bn_cont(x_cont)\n",
    "        x = torch.cat([x, x_cont], 1)\n",
    "\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Embedding sizes\n",
    "cat_sizes = [len(df[col].unique()) for col in categorical_cols]\n",
    "emb_sizes = [(c, min(50, (c+1)//2)) for c in cat_sizes]\n",
    "\n",
    "# Model\n",
    "torch.manual_seed(42)\n",
    "model = TabularModel(emb_sizes, n_cont=len(continuous_cols), out_sz=2)\n",
    "\n",
    "# Loss & optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# -----------------------------\n",
    "# 3. Train Model\n",
    "# -----------------------------\n",
    "epochs = 30\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for x_cat, x_cont, y in train_dl:\n",
    "        optimizer.zero_grad()\n",
    "        preds = model(x_cat, x_cont)\n",
    "        loss = criterion(preds, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    if (epoch+1) % 5 == 0:\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss/len(train_dl):.4f}\")\n",
    "\n",
    "# -----------------------------\n",
    "# 4. Evaluate Model\n",
    "# -----------------------------\n",
    "model.eval()\n",
    "correct, total, test_loss = 0, 0, 0\n",
    "with torch.no_grad():\n",
    "    for x_cat, x_cont, y in test_dl:\n",
    "        preds = model(x_cat, x_cont)\n",
    "        loss = criterion(preds, y)\n",
    "        test_loss += loss.item()\n",
    "        _, predicted = torch.max(preds, 1)\n",
    "        correct += (predicted == y).sum().item()\n",
    "        total += y.size(0)\n",
    "\n",
    "print(f\"\\nTest Loss: {test_loss/len(test_dl):.4f}\")\n",
    "print(f\"Test Accuracy: {100*correct/total:.2f}%\")\n",
    "\n",
    "# -----------------------------\n",
    "# 5. Bonus: Predict New Data\n",
    "# -----------------------------\n",
    "def predict(model, input_dict):\n",
    "    model.eval()\n",
    "    cat_data = [label_encoders[col].transform([input_dict[col]])[0] for col in categorical_cols]\n",
    "    cont_data = [input_dict[col] for col in continuous_cols]\n",
    "    cat_tensor = torch.tensor([cat_data], dtype=torch.int64)\n",
    "    cont_tensor = torch.tensor([cont_data], dtype=torch.float)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        preds = model(cat_tensor, cont_tensor)\n",
    "        _, predicted = torch.max(preds, 1)\n",
    "    return label_encoder.inverse_transform(predicted.numpy())[0]\n",
    "\n",
    "\n",
    "# ### FIX 2: Correct the keys to match the column lists ###\n",
    "new_person = {\n",
    "    \"Workclass\": \"Private\",\n",
    "    \"Education\": \"Bachelors\",\n",
    "    \"Marital Status\": \"Never-married\",\n",
    "    \"Occupation\": \"Adm-clerical\",\n",
    "    \"Relationship\": \"Not-in-family\",\n",
    "    \"Race\": \"White\",\n",
    "    \"Gender\": \"Male\",\n",
    "    \"Native Country\": \"United-States\",\n",
    "    \"Age\": 28,\n",
    "    \"Final Weight\": 338409,\n",
    "    \"EducationNum\": 13,\n",
    "    \"Capital Gain\": 0,\n",
    "    \"capital loss\": 0,\n",
    "    \"Hours per Week\": 40\n",
    "}\n",
    "\n",
    "print(\"\\nPrediction:\", predict(model, new_person))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4f577f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
